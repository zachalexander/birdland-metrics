#!/usr/bin/env python3
"""
Backfill playoff odds history for any completed (or in-progress) season.

Replays the season game-by-game with K=6 ELO, applies preseason ELO regression
at each weekly snapshot, and runs Monte Carlo sims to compute playoff odds over time.

Data sources (all local, no S3 reads):
  - Schedules: model-2026-updates/schedule_{season}_full.csv
  - ELO baselines: model-2026-updates/elo_rating_end_of_{season-1}.csv

Output: playoff-odds-history-{season}.json

Usage:
  python backfill-playoff-odds.py --season 2024 --sims 1000
  python backfill-playoff-odds.py --season 2025 --sims 1000 --upload
"""

import argparse
import json
import logging
import math
from collections import defaultdict
from datetime import date, timedelta
from pathlib import Path

import numpy as np
import pandas as pd

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Constants
# ---------------------------------------------------------------------------

K = 6
HFA = 55
MOV_MULTIPLIER = 2.2
MOV_CAP = 1.25
DEFAULT_SIMS = 1000
PREDICTIONS_BUCKET = "mlb-predictions-2026"

MODEL_DIR = Path(__file__).resolve().parent.parent / "model-2026-updates"

# League & division assignments (canonical codes)
TEAM_LEAGUE = {
    "BAL": "AL", "BOS": "AL", "NYY": "AL", "TB": "AL", "TOR": "AL",
    "CWS": "AL", "CLE": "AL", "DET": "AL", "KC": "AL", "MIN": "AL",
    "HOU": "AL", "LAA": "AL", "ATH": "AL", "SEA": "AL", "TEX": "AL",
    "ATL": "NL", "MIA": "NL", "NYM": "NL", "PHI": "NL", "WSH": "NL",
    "CHC": "NL", "CIN": "NL", "MIL": "NL", "PIT": "NL", "STL": "NL",
    "AZ": "NL", "COL": "NL", "LAD": "NL", "SD": "NL", "SF": "NL",
}

TEAM_DIVISION = {
    "BAL": "AL East", "BOS": "AL East", "NYY": "AL East", "TB": "AL East", "TOR": "AL East",
    "CWS": "AL Central", "CLE": "AL Central", "DET": "AL Central", "KC": "AL Central", "MIN": "AL Central",
    "HOU": "AL West", "LAA": "AL West", "ATH": "AL West", "SEA": "AL West", "TEX": "AL West",
    "ATL": "NL East", "MIA": "NL East", "NYM": "NL East", "PHI": "NL East", "WSH": "NL East",
    "CHC": "NL Central", "CIN": "NL Central", "MIL": "NL Central", "PIT": "NL Central", "STL": "NL Central",
    "AZ": "NL West", "COL": "NL West", "LAD": "NL West", "SD": "NL West", "SF": "NL West",
}

# Season date ranges (first game through last regular-season Monday snapshot)
SEASON_DATES = {
    2024: (date(2024, 3, 18), date(2024, 9, 30)),
    2025: (date(2025, 3, 24), date(2025, 9, 29)),
}

# ---------------------------------------------------------------------------
# ELO math (inlined to avoid config.py env-var dependency)
# ---------------------------------------------------------------------------

def expected_score(elo_a: float, elo_b: float, hfa: float = 0.0) -> float:
    return 1.0 / (1.0 + 10.0 ** ((elo_b - (elo_a + hfa)) / 400.0))


def mov_mult(score_diff: int, elo_diff: float) -> float:
    raw = math.log(abs(score_diff) + 1) * (MOV_MULTIPLIER / (0.001 * abs(elo_diff) + MOV_MULTIPLIER))
    return min(raw, MOV_CAP)


def elo_shift(elo: float, exp: float, actual: float, mov: float = 1.0) -> float:
    return K * mov * (actual - exp)


# ---------------------------------------------------------------------------
# Data loading
# ---------------------------------------------------------------------------

def load_prior_season_elo(season: int) -> dict[str, float]:
    """
    Load preseason ELO for the given season. Tries two sources in order:
    1. preseason_elo_{season}.csv — includes mean reversion + WAR adjustments
    2. elo_rating_end_of_{season-1}.csv — raw end-of-season with inline 1/3 mean reversion
    """
    # Try preseason file first (generated by generate-preseason-elo.py)
    preseason_path = MODEL_DIR / f"preseason_elo_{season}.csv"
    if preseason_path.exists():
        df = pd.read_csv(preseason_path)
        baseline = {row["team"]: float(row["preseason_elo"]) for _, row in df.iterrows()}
        logger.info(f"Loaded {len(baseline)} preseason ELOs from {preseason_path.name} (mean reversion + WAR)")
        return baseline

    # Fallback: raw end-of-season ELO with inline 40% mean reversion
    path = MODEL_DIR / f"elo_rating_end_of_{season - 1}.csv"
    df = pd.read_csv(path)
    baseline = {}
    for _, row in df.iterrows():
        raw_elo = float(row["elo"])
        baseline[row["team"]] = 0.6 * raw_elo + 0.4 * 1500
    logger.info(f"Loaded {len(baseline)} team ELOs from {path.name} (with 40% mean reversion fallback)")
    return baseline


def load_schedule(season: int) -> pd.DataFrame:
    """Load full season schedule CSV. Filters to completed ('Final') games."""
    path = MODEL_DIR / f"schedule_{season}_full.csv"
    df = pd.read_csv(path)
    df["date"] = pd.to_datetime(df["date"])
    # Only use completed games
    completed = df[df["status"] == "Final"].copy()
    completed = completed.sort_values("date").reset_index(drop=True)
    logger.info(f"Loaded {len(completed)} completed games from {path.name}")
    return completed


# ---------------------------------------------------------------------------
# Core ELO replay
# ---------------------------------------------------------------------------

def replay_elo_to_date(
    schedule_df: pd.DataFrame,
    preseason_elo: dict[str, float],
    cutoff_date: pd.Timestamp,
) -> tuple[dict[str, float], dict[str, int]]:
    """
    Replay all completed games before cutoff_date using K=6 ELO.

    Returns (current_elo, games_played_per_team).
    """
    current_elo = dict(preseason_elo)
    games_played = defaultdict(int)

    before = schedule_df[schedule_df["date"] < cutoff_date]

    for _, row in before.iterrows():
        home = row["homeTeam"]
        away = row["awayTeam"]
        h_score = row["homeScore"]
        a_score = row["awayScore"]

        if home not in current_elo or away not in current_elo:
            continue

        h_elo = current_elo[home]
        a_elo = current_elo[away]

        exp_h = expected_score(h_elo, a_elo, hfa=HFA)
        score_diff = abs(h_score - a_score)
        elo_diff = h_elo + HFA - a_elo

        m = mov_mult(score_diff, elo_diff)
        actual_h = 1.0 if h_score > a_score else 0.0

        shift = elo_shift(h_elo, exp_h, actual_h, m)
        current_elo[home] = h_elo + shift
        current_elo[away] = a_elo - shift

        games_played[home] += 1
        games_played[away] += 1

    return current_elo, dict(games_played)


FADE_GAMES = 100  # Games until preseason influence fully fades (backtest-optimal)


def fade_pct(gp: int, curve: str) -> float:
    """
    Compute the current-ELO weight (0→1) based on games played and fade curve.
    At gp=0 returns 0 (100% preseason), at gp>=FADE_GAMES returns 1 (100% current).
    """
    if gp >= FADE_GAMES:
        return 1.0
    t = gp / float(FADE_GAMES)  # normalized 0→1
    if curve == "linear":
        return t
    elif curve == "cosine":
        return 0.5 * (1.0 - math.cos(math.pi * t))
    elif curve == "sigmoid":
        k = 10  # steepness — higher = sharper transition in the middle
        return 1.0 / (1.0 + math.exp(-k * (t - 0.5)))
    elif curve == "quadratic":
        return 1.0 - (1.0 - t) ** 2
    else:
        raise ValueError(f"Unknown fade curve: {curve}")


def regress_elo(
    current_elo: dict[str, float],
    preseason_elo: dict[str, float],
    games_played: dict[str, int],
    curve: str = "linear",
) -> dict[str, float]:
    """
    Regress current ELO toward preseason baseline using the specified fade curve.
    regressed = pct * current + (1-pct) * preseason
    """
    regressed = {}
    for team, cur in current_elo.items():
        gp = games_played.get(team, 0)
        pct = fade_pct(gp, curve)
        pre = preseason_elo.get(team, cur)
        regressed[team] = pct * cur + (1.0 - pct) * pre
    return regressed


# ---------------------------------------------------------------------------
# Monte Carlo simulation
# ---------------------------------------------------------------------------

def simulate_remaining(
    remaining_df: pd.DataFrame,
    regressed_elo: dict[str, float],
    actual_wins: dict[str, int],
    actual_losses: dict[str, int],
    sim_count: int,
) -> np.ndarray:
    """
    Monte Carlo simulation of remaining games.
    Seeds with actual W-L, then simulates remaining games using ELO probabilities.

    Returns sim_matrix of shape (sim_count, num_teams) with total wins per sim.
    """
    all_teams = sorted(regressed_elo.keys())
    team_idx = {t: i for i, t in enumerate(all_teams)}
    n = len(all_teams)

    sim_matrix = np.zeros((sim_count, n))

    # Seed with actual wins
    for team, idx in team_idx.items():
        sim_matrix[:, idx] = actual_wins.get(team, 0)

    # Simulate remaining games
    for _, row in remaining_df.iterrows():
        home = row["homeTeam"]
        away = row["awayTeam"]

        if home not in regressed_elo or away not in regressed_elo:
            continue

        p_home = expected_score(regressed_elo[home], regressed_elo[away], hfa=HFA)
        draws = np.random.rand(sim_count)
        home_wins = draws < p_home
        sim_matrix[:, team_idx[home]] += home_wins.astype(int)
        sim_matrix[:, team_idx[away]] += (~home_wins).astype(int)

    return sim_matrix, all_teams, team_idx


def compute_al_playoff_odds(
    sim_matrix: np.ndarray,
    all_teams: list[str],
    team_idx: dict[str, int],
    sim_count: int,
) -> dict[str, dict[str, float]]:
    """
    Compute AL playoff odds: 3 division winners + 3 wild cards.
    Returns {team: {playoff_pct, division_pct, wildcard_pct}}.
    """
    al_teams = [t for t in all_teams if TEAM_LEAGUE.get(t) == "AL"]

    al_divisions: dict[str, list[str]] = {}
    for t in al_teams:
        div = TEAM_DIVISION.get(t, "Unknown")
        al_divisions.setdefault(div, []).append(t)

    playoff_count: dict[str, int] = defaultdict(int)
    division_count: dict[str, int] = defaultdict(int)
    wildcard_count: dict[str, int] = defaultdict(int)

    for sim_idx in range(sim_count):
        al_wins = {t: sim_matrix[sim_idx, team_idx[t]] for t in al_teams}

        # Division winners (tiebreak by random for now — noise is fine at 1000 sims)
        div_winners = set()
        for div, div_teams in al_divisions.items():
            winner = max(div_teams, key=lambda t: (al_wins[t], np.random.rand()))
            div_winners.add(winner)
            division_count[winner] += 1

        # Wild cards: top 3 non-division-winners by wins
        remaining = [(t, al_wins[t]) for t in al_teams if t not in div_winners]
        remaining.sort(key=lambda x: (x[1], np.random.rand()), reverse=True)
        wc_teams = {t for t, _ in remaining[:3]}
        for t in wc_teams:
            wildcard_count[t] += 1

        for t in div_winners | wc_teams:
            playoff_count[t] += 1

    results = {}
    for t in al_teams:
        results[t] = {
            "playoff_pct": round(100.0 * playoff_count[t] / sim_count, 1),
            "division_pct": round(100.0 * division_count[t] / sim_count, 1),
            "wildcard_pct": round(100.0 * wildcard_count[t] / sim_count, 1),
        }
    return results


# ---------------------------------------------------------------------------
# Snapshot computation
# ---------------------------------------------------------------------------

def get_monday_dates(start: date, end: date) -> list[date]:
    current = start
    while current.weekday() != 0:
        current += timedelta(days=1)
    dates = []
    while current <= end:
        dates.append(current)
        current += timedelta(days=7)
    return dates


def compute_all_snapshots(
    schedule_df: pd.DataFrame,
    preseason_elo: dict[str, float],
    season: int,
    sim_count: int,
    fade_curve: str = "linear",
) -> list[dict]:
    start, end = SEASON_DATES[season]
    mondays = get_monday_dates(start, end)
    logger.info(f"Computing {len(mondays)} weekly snapshots for {season} (fade={fade_curve})")

    all_results = []

    for i, snap_date in enumerate(mondays):
        snap_ts = pd.Timestamp(snap_date)

        # 1. Replay ELO to this date
        current_elo, games_played = replay_elo_to_date(schedule_df, preseason_elo, snap_ts)

        # 2. Regress toward preseason
        regressed = regress_elo(current_elo, preseason_elo, games_played, fade_curve)

        # 3. Compute actual W-L before cutoff
        before = schedule_df[schedule_df["date"] < snap_ts]
        actual_wins: dict[str, int] = defaultdict(int)
        actual_losses: dict[str, int] = defaultdict(int)
        for _, row in before.iterrows():
            h, a = row["homeTeam"], row["awayTeam"]
            if row["homeScore"] > row["awayScore"]:
                actual_wins[h] += 1
                actual_losses[a] += 1
            else:
                actual_wins[a] += 1
                actual_losses[h] += 1

        # 4. Build remaining schedule
        remaining = schedule_df[schedule_df["date"] >= snap_ts]

        # 5. Simulate
        sim_matrix, all_teams, team_idx = simulate_remaining(
            remaining, regressed, actual_wins, actual_losses, sim_count
        )

        # 6. Compute AL playoff odds
        odds = compute_al_playoff_odds(sim_matrix, all_teams, team_idx, sim_count)

        date_str = snap_date.isoformat()
        for team, team_odds in odds.items():
            all_results.append({
                "date": date_str,
                "team": team,
                "playoff_pct": team_odds["playoff_pct"],
                "division_pct": team_odds["division_pct"],
                "wildcard_pct": team_odds["wildcard_pct"],
            })

        # Log BAL snapshot
        bal = odds.get("BAL", {})
        logger.info(
            f"  [{i+1}/{len(mondays)}] {snap_date}  "
            f"BAL: {bal.get('playoff_pct', 0)}% playoff, {bal.get('division_pct', 0)}% div"
        )

    return all_results


# ---------------------------------------------------------------------------
# Main
# ---------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="Backfill playoff odds history for a given season")
    parser.add_argument("--season", type=int, required=True, choices=list(SEASON_DATES.keys()),
                        help="Season year to backfill (2024 or 2025)")
    parser.add_argument("--sims", type=int, default=DEFAULT_SIMS, help="Monte Carlo sims per snapshot")
    parser.add_argument("--fade-curve", type=str, default="linear",
                        choices=["linear", "cosine", "sigmoid", "quadratic"],
                        help="Fade curve for preseason→in-season ELO transition")
    parser.add_argument("--upload", action="store_true", help="Upload result to S3")
    parser.add_argument("--output", type=str, default=None, help="Local output file path override")
    args = parser.parse_args()

    season = args.season
    fade_curve = args.fade_curve

    logger.info(f"Backfilling {season} season with K={K}, HFA={HFA}, {args.sims} sims/snapshot, fade={fade_curve}")

    preseason_elo = load_prior_season_elo(season)
    schedule_df = load_schedule(season)

    all_results = compute_all_snapshots(schedule_df, preseason_elo, season, args.sims, fade_curve)

    al_teams_per_snap = len([t for t in TEAM_LEAGUE if TEAM_LEAGUE[t] == "AL"])
    n_snaps = len(all_results) // al_teams_per_snap if al_teams_per_snap else 0
    logger.info(f"Total: {len(all_results)} rows ({n_snaps} snapshots × {al_teams_per_snap} AL teams)")

    # Save locally
    output_path = args.output or f"playoff-odds-history-{season}-{fade_curve}.json"
    with open(output_path, "w") as f:
        json.dump(all_results, f, indent=2)
    logger.info(f"Wrote {output_path}")

    # Upload to S3
    if args.upload:
        import boto3
        s3 = boto3.client("s3")
        key = f"playoff-odds-history-{season}.json"
        s3.put_object(
            Bucket=PREDICTIONS_BUCKET,
            Key=key,
            Body=json.dumps(all_results),
            ContentType="application/json",
            CacheControl="no-cache, must-revalidate",
        )
        logger.info(f"Uploaded to s3://{PREDICTIONS_BUCKET}/{key}")


if __name__ == "__main__":
    main()
